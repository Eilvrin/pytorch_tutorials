{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc1af48-b6ef-4c53-95af-52125893e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0251,  0.0559, -0.0631,  ...,  0.0972,  0.0378,  0.0354],\n",
      "        [ 0.0720, -0.0330,  0.0335,  ...,  0.0809, -0.0304, -0.0005],\n",
      "        [-0.0671,  0.0400,  0.0385,  ...,  0.0914,  0.0082,  0.0758],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0735,  0.0412,  ...,  0.0411,  0.0482,  0.0262],\n",
      "        [-0.0362,  0.0759, -0.0943,  ...,  0.0613, -0.0939, -0.0570],\n",
      "        [-0.0079, -0.0826, -0.0188,  ..., -0.0682, -0.0169, -0.0575]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0355, -0.0249, -0.0187,  0.0687,  0.0335,  0.0260,  0.0341,  0.0950,\n",
      "         0.0781, -0.0758, -0.0838,  0.0340,  0.0447, -0.0077, -0.0992,  0.0946,\n",
      "        -0.0007, -0.0339, -0.0785,  0.0327, -0.0036,  0.0990, -0.0907, -0.0399,\n",
      "        -0.0172,  0.0697,  0.0107,  0.0882, -0.0710,  0.0457, -0.0291, -0.0082,\n",
      "        -0.0975,  0.0384,  0.0961,  0.0160, -0.0249,  0.0674, -0.0414, -0.0283,\n",
      "         0.0529,  0.0939,  0.0279, -0.0948, -0.0068,  0.0770,  0.0269,  0.0110,\n",
      "        -0.0084, -0.0181,  0.0151, -0.0271, -0.0772, -0.0236, -0.0004, -0.0139,\n",
      "         0.0660,  0.0732,  0.0276, -0.0789,  0.0008,  0.0499, -0.0736,  0.0462,\n",
      "        -0.0642,  0.0813,  0.0130,  0.0114, -0.0306,  0.0134, -0.0222,  0.0645,\n",
      "        -0.0002,  0.0831,  0.0709,  0.0118,  0.0954, -0.0285,  0.0758,  0.0376,\n",
      "         0.0008,  0.0607,  0.0062,  0.0728,  0.0340,  0.0155,  0.0288, -0.0029,\n",
      "        -0.0430,  0.0063, -0.0816, -0.0729,  0.0727,  0.0662, -0.0666,  0.0428,\n",
      "         0.0946, -0.0472,  0.0598, -0.0534,  0.0013, -0.0159, -0.0034,  0.0921,\n",
      "        -0.0848,  0.0099, -0.0808, -0.0749, -0.0921,  0.0231,  0.0714, -0.0746,\n",
      "        -0.0586, -0.0591,  0.0349,  0.0759, -0.0292,  0.0825,  0.0777,  0.0754,\n",
      "         0.0348,  0.0608,  0.0771,  0.0093, -0.0540,  0.0579,  0.0147, -0.0328,\n",
      "         0.0510, -0.0635,  0.0551,  0.0472,  0.0472, -0.0445, -0.0505,  0.0330,\n",
      "         0.0583,  0.0912,  0.0316,  0.0557,  0.0865,  0.0817,  0.0002, -0.0697,\n",
      "         0.0201,  0.0165,  0.0542,  0.0483,  0.0885, -0.0492,  0.0591,  0.0312,\n",
      "        -0.0101, -0.0591, -0.0205,  0.0267,  0.0024,  0.0838, -0.0017,  0.0527,\n",
      "         0.0483,  0.0152, -0.0512,  0.0351, -0.0661, -0.0154, -0.0458, -0.0590,\n",
      "         0.0389, -0.0018, -0.0070,  0.0243, -0.0011, -0.0016,  0.0830, -0.0015,\n",
      "        -0.0677, -0.0212,  0.0691, -0.0016,  0.0724, -0.0846,  0.0868,  0.0092,\n",
      "        -0.0299, -0.0773, -0.0545, -0.0685, -0.0094, -0.0549,  0.0184,  0.0940,\n",
      "        -0.0807, -0.0806, -0.0775,  0.0003,  0.0460, -0.0427,  0.0797,  0.0789],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0602,  0.0340, -0.0675,  ...,  0.0414, -0.0325,  0.0271],\n",
      "        [ 0.0676,  0.0299, -0.0182,  ...,  0.0131,  0.0552, -0.0156],\n",
      "        [-0.0299, -0.0273,  0.0567,  ..., -0.0612, -0.0592, -0.0503],\n",
      "        ...,\n",
      "        [-0.0656, -0.0625,  0.0208,  ..., -0.0194, -0.0517, -0.0170],\n",
      "        [ 0.0241, -0.0177, -0.0297,  ...,  0.0312,  0.0384,  0.0702],\n",
      "        [ 0.0073, -0.0022,  0.0577,  ..., -0.0173, -0.0485, -0.0114]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0198,  0.0344, -0.0182, -0.0093, -0.0633, -0.0108, -0.0376, -0.0380,\n",
      "        -0.0275, -0.0329], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0602,  0.0340, -0.0675,  ...,  0.0414, -0.0325,  0.0271],\n",
      "        [ 0.0676,  0.0299, -0.0182,  ...,  0.0131,  0.0552, -0.0156],\n",
      "        [-0.0299, -0.0273,  0.0567,  ..., -0.0612, -0.0592, -0.0503],\n",
      "        ...,\n",
      "        [-0.0656, -0.0625,  0.0208,  ..., -0.0194, -0.0517, -0.0170],\n",
      "        [ 0.0241, -0.0177, -0.0297,  ...,  0.0312,  0.0384,  0.0702],\n",
      "        [ 0.0073, -0.0022,  0.0577,  ..., -0.0173, -0.0485, -0.0114]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0198,  0.0344, -0.0182, -0.0093, -0.0633, -0.0108, -0.0376, -0.0380,\n",
      "        -0.0275, -0.0329], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c9f0fc-9b62-48ad-a7d1-349927d98457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.1529, 0.6699, 0.8536]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.4029, -0.1462,  0.5251],\n",
      "        [ 0.1011,  0.3084, -0.2215]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3361, 0.2033], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[0.7480, 0.2362]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0313e0f3-d1cb-4b4a-940c-e385f359e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469bd182-8acb-4064-87a7-b74ec0c2a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804381f6-2195-4cba-a984-539431e54683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4181, 0.4854, 0.5844, 0.7842, 0.0857, 0.9015],\n",
      "         [0.2042, 0.9203, 0.2875, 0.4005, 0.8723, 0.9065],\n",
      "         [0.1713, 0.7567, 0.1340, 0.7769, 0.8918, 0.7976],\n",
      "         [0.8905, 0.3588, 0.8119, 0.2661, 0.5067, 0.3514],\n",
      "         [0.1560, 0.4164, 0.3195, 0.8881, 0.3984, 0.4312],\n",
      "         [0.7907, 0.4670, 0.4179, 0.5776, 0.9819, 0.8852]]])\n",
      "tensor([[[0.9203, 0.9065],\n",
      "         [0.8905, 0.9819]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55e8a41-6861-4253-94e6-c952b8c8ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[24.5237, 12.0617, 11.2152,  5.4603],\n",
      "         [21.5989, 24.5511, 15.7727, 12.9225],\n",
      "         [10.4666, 23.1640,  6.8282, 23.9101],\n",
      "         [15.6578,  7.9309, 22.1772, 24.9522]]])\n",
      "tensor(16.4496)\n",
      "tensor([[[ 1.6123, -0.1803, -0.3021, -1.1299],\n",
      "         [ 0.6279,  1.2699, -0.6390, -1.2588],\n",
      "         [-0.7442,  0.9355, -1.2254,  1.0341],\n",
      "         [-0.3081, -1.4856,  0.6854,  1.1083]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(5.0291e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68a7e70-61bf-40c0-805e-823ce75a4278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3510, 1.2122, 1.6399, 0.1124],\n",
      "         [0.0000, 0.5110, 0.0000, 0.0000],\n",
      "         [0.2476, 0.0000, 1.6213, 0.0000],\n",
      "         [1.5039, 0.8329, 0.0000, 1.1681]]])\n",
      "tensor([[[0.3510, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.5110, 0.6878, 1.5549],\n",
      "         [0.2476, 0.0000, 0.0000, 0.0000],\n",
      "         [1.5039, 0.0000, 1.1585, 1.1681]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a3295-b7f0-41fa-9861-9631dab4e8d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

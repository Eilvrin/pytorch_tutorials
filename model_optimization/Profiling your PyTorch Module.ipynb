{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.autograd.profiler as profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "\n",
    "    def forward(self, input, mask):\n",
    "        with profiler.record_function(\"LINEAR PASS\"):\n",
    "            out = self.linear(input)\n",
    "\n",
    "        with profiler.record_function(\"MASK INDICES\"):\n",
    "            threshold = out.sum(axis=1).mean().item()\n",
    "            hi_idx = np.argwhere(mask.cpu().numpy() > threshold)\n",
    "            hi_idx = torch.from_numpy(hi_idx).cuda()\n",
    "\n",
    "        return out, hi_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModule(500, 10).cuda()\n",
    "input = torch.rand(128, 500).cuda()\n",
    "mask = torch.rand((500, 500, 500), dtype=torch.double).cuda()\n",
    "\n",
    "# warm-up\n",
    "model(input, mask)\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    out, idx = model(input, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     MASK INDICES        87.92%        5.124s        99.95%        5.825s        5.825s           0 b    -953.67 Mb             1  \n",
      "                                  cudaMemcpyAsync        12.02%     700.574ms        12.02%     700.574ms     233.525ms           0 b           0 b             3  \n",
      "                                      aten::addmm         0.02%       1.404ms         0.03%       1.768ms       1.768ms           0 b           0 b             1  \n",
      "                                     aten::linear         0.01%     635.090us         0.04%       2.456ms       2.456ms           0 b           0 b             1  \n",
      "                                      LINEAR PASS         0.01%     620.433us         0.05%       3.076ms       3.076ms           0 b           0 b             1  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.828s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     MASK INDICES        66.26%     317.525ms        99.71%     477.853ms     477.853ms           0 b    -476.84 Mb             1  \n",
      "                                  cudaMemcpyAsync        33.41%     160.092ms        33.41%     160.092ms      80.046ms           0 b           0 b             2  \n",
      "                                      aten::addmm         0.24%       1.172ms         0.25%       1.196ms       1.196ms           0 b           0 b             1  \n",
      "                                      LINEAR PASS         0.03%     144.225us         0.29%       1.388ms       1.388ms           0 b           0 b             1  \n",
      "                                      aten::copy_         0.01%      40.911us        33.41%     160.131ms      80.066ms           0 b           0 b             2  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 479.241ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyModule(500, 10).cuda()\n",
    "input = torch.rand(128, 500).cuda()\n",
    "mask = torch.rand((500, 500, 500), dtype=torch.float).cuda()\n",
    "\n",
    "# warm-up\n",
    "model(input, mask)\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    out, idx = model(input, mask)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaStreamSynchronize        92.88%      25.303ms        92.88%      25.303ms      25.303ms           0 b           0 b             1  \n",
      "                                          aten::nonzero         1.62%     442.665us        95.76%      26.086ms      26.086ms           0 b           0 b             1  \n",
      "                                           aten::unbind         1.15%     313.742us         1.22%     330.981us     330.981us           0 b           0 b             1  \n",
      "                                            aten::addmm         0.85%     232.024us         0.93%     254.347us     254.347us           0 b           0 b             1  \n",
      "                                             aten::set_         0.84%     230.173us         0.84%     230.173us     230.173us           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 27.241ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "\n",
    "    def forward(self, input, mask):\n",
    "        with profiler.record_function(\"LINEAR PASS\"):\n",
    "            out = self.linear(input)\n",
    "\n",
    "        with profiler.record_function(\"MASK INDICES\"):\n",
    "            threshold = out.sum(axis=1).mean()\n",
    "            hi_idx = (mask > threshold).nonzero(as_tuple=True)\n",
    "\n",
    "        return out, hi_idx\n",
    "\n",
    "\n",
    "model = MyModule(500, 10).cuda()\n",
    "input = torch.rand(128, 500).cuda()\n",
    "mask = torch.rand((500, 500, 500), dtype=torch.float).cuda()\n",
    "\n",
    "# warm-up\n",
    "model(input, mask)\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    out, idx = model(input, mask)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

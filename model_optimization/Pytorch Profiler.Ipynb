{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "inputs = torch.rand(5, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference         6.35%      12.812ms       100.00%     201.804ms     201.804ms             1  \n",
      "                     aten::conv2d         0.56%       1.138ms        70.81%     142.900ms       7.145ms            20  \n",
      "                aten::convolution         0.75%       1.520ms        70.25%     141.762ms       7.088ms            20  \n",
      "               aten::_convolution         0.54%       1.091ms        69.49%     140.242ms       7.012ms            20  \n",
      "         aten::mkldnn_convolution        68.21%     137.652ms        68.95%     139.151ms       6.958ms            20  \n",
      "                 aten::batch_norm         0.07%     144.999us         7.49%      15.114ms     755.709us            20  \n",
      "     aten::_batch_norm_impl_index         0.35%     699.337us         7.42%      14.969ms     748.459us            20  \n",
      "          aten::native_batch_norm         6.85%      13.821ms         7.05%      14.231ms     711.569us            20  \n",
      "                 aten::max_pool2d         0.02%      34.618us         6.97%      14.072ms      14.072ms             1  \n",
      "    aten::max_pool2d_with_indices         6.96%      14.037ms         6.96%      14.037ms      14.037ms             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 201.804ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                  model_inference         6.35%      12.812ms       100.00%     201.804ms     201.804ms             1                                                                                []  \n",
      "                     aten::conv2d         0.37%     751.879us        20.13%      40.619ms      40.619ms             1                             [[5, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "                aten::convolution         0.51%       1.023ms        19.76%      39.867ms      39.867ms             1                     [[5, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], []]  \n",
      "               aten::_convolution         0.38%     757.961us        19.25%      38.844ms      38.844ms             1     [[5, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "         aten::mkldnn_convolution        18.35%      37.032ms        18.87%      38.086ms      38.086ms             1                             [[5, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "                     aten::conv2d         0.02%      45.634us        13.50%      27.247ms       6.812ms             4                             [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]  \n",
      "                aten::convolution         0.07%     135.884us        13.48%      27.201ms       6.800ms             4                     [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], []]  \n",
      "               aten::_convolution         0.05%      91.901us        13.41%      27.065ms       6.766ms             4     [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "         aten::mkldnn_convolution        13.30%      26.837ms        13.37%      26.973ms       6.743ms             4                             [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [], [], []]  \n",
      "                     aten::conv2d         0.02%      33.099us         9.13%      18.428ms       6.143ms             3                          [[5, 128, 28, 28], [128, 128, 3, 3], [], [], [], [], []]  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 201.804ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     254.887ms      7142.60%     254.887ms     127.443ms             2  \n",
      "                                        model_inference         0.59%       2.912ms       100.00%     496.705ms     496.705ms       0.000us         0.00%       3.569ms       3.569ms             1  \n",
      "                                           aten::conv2d         0.02%      75.109us        68.24%     338.968ms      16.948ms       0.000us         0.00%       2.198ms     109.884us            20  \n",
      "                                      aten::convolution         0.05%     240.089us        68.23%     338.893ms      16.945ms       0.000us         0.00%       2.198ms     109.884us            20  \n",
      "                                     aten::_convolution         0.16%     802.979us        68.18%     338.653ms      16.933ms       0.000us         0.00%       2.198ms     109.884us            20  \n",
      "                                aten::cudnn_convolution        41.83%     207.791ms        68.02%     337.850ms      16.893ms       2.198ms        61.58%       2.198ms     109.884us            20  \n",
      "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     784.842us        21.99%     784.842us      23.084us            34  \n",
      "                                       aten::batch_norm         0.01%      47.946us         5.48%      27.228ms       1.361ms       0.000us         0.00%     677.323us      33.866us            20  \n",
      "                           aten::_batch_norm_impl_index         0.02%     107.830us         5.47%      27.181ms       1.359ms       0.000us         0.00%     677.323us      33.866us            20  \n",
      "                                 aten::cudnn_batch_norm         2.81%      13.941ms         5.45%      27.073ms       1.354ms     677.323us        18.98%     677.323us      33.866us            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 496.727ms\n",
      "Self CUDA time total: 3.569ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.xpu.is_available():\n",
    "    device = 'xpu'\n",
    "else:\n",
    "    print('Neither CUDA nor XPU devices are available to demonstrate profiling on acceleration devices')\n",
    "    import sys\n",
    "    sys.exit(0)\n",
    "\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA, ProfilerActivity.XPU]\n",
    "sort_by_keyword = device + \"_time_total\"\n",
    "\n",
    "model = models.resnet18().to(device)\n",
    "inputs = torch.randn(5, 3, 224, 224).to(device)\n",
    "\n",
    "with profile(activities=activities, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         0.51%     626.548us         0.51%     626.548us       3.133us      94.86 Mb      94.86 Mb           200  \n",
      "    aten::max_pool2d_with_indices         8.33%      10.255ms         8.33%      10.255ms      10.255ms      11.48 Mb      11.48 Mb             1  \n",
      "                      aten::addmm         0.10%     123.735us         0.11%     138.343us     138.343us      19.53 Kb      19.53 Kb             1  \n",
      "                       aten::mean         0.02%      25.539us         0.10%     121.905us     121.905us      10.00 Kb      10.00 Kb             1  \n",
      "              aten::empty_strided         0.00%       5.546us         0.00%       5.546us       5.546us           4 b           4 b             1  \n",
      "                     aten::conv2d         0.11%     140.831us        74.85%      92.152ms       4.608ms      47.37 Mb           0 b            20  \n",
      "                aten::convolution         0.33%     402.778us        74.74%      92.011ms       4.601ms      47.37 Mb           0 b            20  \n",
      "               aten::_convolution         0.20%     247.134us        74.41%      91.608ms       4.580ms      47.37 Mb           0 b            20  \n",
      "         aten::mkldnn_convolution        73.81%      90.868ms        74.21%      91.361ms       4.568ms      47.37 Mb           0 b            20  \n",
      "                aten::as_strided_         0.13%     159.260us         0.13%     159.260us       7.963us           0 b           0 b            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 123.112ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "inputs = torch.rand(5, 3, 224, 224)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::empty         0.51%     626.548us         0.51%     626.548us       3.133us      94.86 Mb      94.86 Mb           200  \n",
      "                 aten::batch_norm         0.10%     119.814us        10.62%      13.070ms     653.481us      47.41 Mb           0 b            20  \n",
      "     aten::_batch_norm_impl_index         0.18%     224.671us        10.52%      12.950ms     647.491us      47.41 Mb           0 b            20  \n",
      "          aten::native_batch_norm         9.99%      12.301ms        10.30%      12.685ms     634.231us      47.41 Mb     -75.00 Kb            20  \n",
      "                     aten::conv2d         0.11%     140.831us        74.85%      92.152ms       4.608ms      47.37 Mb           0 b            20  \n",
      "                aten::convolution         0.33%     402.778us        74.74%      92.011ms       4.601ms      47.37 Mb           0 b            20  \n",
      "               aten::_convolution         0.20%     247.134us        74.41%      91.608ms       4.580ms      47.37 Mb           0 b            20  \n",
      "         aten::mkldnn_convolution        73.81%      90.868ms        74.21%      91.361ms       4.568ms      47.37 Mb           0 b            20  \n",
      "                 aten::empty_like         0.08%     100.326us         0.14%     174.817us       8.741us      47.37 Mb           0 b            20  \n",
      "                 aten::max_pool2d         0.01%      15.601us         8.34%      10.271ms      10.271ms      11.48 Mb           0 b             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 123.112ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA, ProfilerActivity.XPU]\n",
    "\n",
    "model = models.resnet18().to(device)\n",
    "inputs = torch.randn(5, 3, 224, 224).to(device)\n",
    "\n",
    "with profile(activities=activities) as prof:\n",
    "    model(inputs)\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::cudnn_convolution        22.90%       1.443ms        37.89%       2.387ms     119.368us       2.168ms        61.31%       2.168ms     108.399us            20  \n",
      "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     766.033us        21.66%     766.033us      22.530us            34  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 6.300ms\n",
      "Self CUDA time total: 3.536ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sort_by_keyword = \"self_\" + device + \"_time_total\"\n",
    "\n",
    "with profile(\n",
    "    activities=activities,\n",
    "    with_stack=True,\n",
    ") as prof:\n",
    "    model(inputs)\n",
    "\n",
    "# Print aggregated stats\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import schedule\n",
    "\n",
    "my_schedule = schedule(\n",
    "    skip_first=10,\n",
    "    wait=5,\n",
    "    warmup=1,\n",
    "    active=3,\n",
    "    repeat=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us      13.804ms       174.85%      13.804ms       6.902ms             2  \n",
      "                                aten::cudnn_convolution        12.61%       1.927ms        20.31%       3.104ms      77.610us       5.170ms        65.48%       5.170ms     129.242us            40  \n",
      "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.515ms        19.19%       1.515ms      22.275us            68  \n",
      "                                 aten::cudnn_batch_norm        11.31%       1.728ms        25.53%       3.902ms      97.538us       1.338ms        16.95%       1.338ms      33.451us            40  \n",
      "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us       1.213ms        15.36%       1.213ms     202.100us             6  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     655.470us         8.30%     655.470us      81.934us             8  \n",
      "                                       aten::clamp_min_         2.14%     327.775us         3.63%     555.268us      16.331us     652.361us         8.26%     652.361us      19.187us            34  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     652.361us         8.26%     652.361us      19.187us            34  \n",
      "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us     501.867us         6.36%     501.867us      16.729us            30  \n",
      "void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s168...         0.00%       0.000us         0.00%       0.000us       0.000us     451.177us         5.71%     451.177us      56.397us             8  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 15.284ms\n",
      "Self CUDA time total: 7.895ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us       9.838ms       109.27%       9.838ms       4.919ms             2  \n",
      "                                aten::cudnn_convolution        11.81%       1.164ms        18.80%       1.853ms      46.327us       5.267ms        58.50%       5.267ms     131.664us            40  \n",
      "                                 aten::cudnn_batch_norm        10.75%       1.059ms        23.51%       2.317ms      57.914us       2.312ms        25.69%       2.312ms      57.811us            40  \n",
      "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.525ms        16.94%       1.525ms      22.423us            68  \n",
      "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us       1.414ms        15.70%       1.414ms     706.812us             2  \n",
      "sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us       1.253ms        13.92%       1.253ms     208.862us             6  \n",
      "                                       aten::clamp_min_         2.00%     196.634us         3.86%     380.753us      11.199us     673.996us         7.49%     673.996us      19.823us            34  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     673.996us         7.49%     673.996us      19.823us            34  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     654.027us         7.26%     654.027us      81.753us             8  \n",
      "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us     499.116us         5.54%     499.116us      16.637us            30  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 9.855ms\n",
      "Self CUDA time total: 9.003ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sort_by_keyword = \"self_\" + device + \"_time_total\"\n",
    "\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=sort_by_keyword, row_limit=10)\n",
    "    print(output)\n",
    "    p.export_chrome_trace(\"/tmp/trace_\" + str(p.step_num) + \".json\")\n",
    "\n",
    "with profile(\n",
    "    activities=activities,\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=2),\n",
    "    on_trace_ready=trace_handler\n",
    ") as p:\n",
    "    for idx in range(8):\n",
    "        model(inputs)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
